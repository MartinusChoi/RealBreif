{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51f03aa1",
   "metadata": {},
   "source": [
    "## Import & Basic Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ea5fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/company_breif_pjt/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/company_breif_pjt/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from keybert import KeyBERT\n",
    "from transformers import BertModel\n",
    "\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ecf966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(os.path.join(\"config\", \".env\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca650004",
   "metadata": {},
   "source": [
    "## Construct Eval Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9380be53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TL_인공물_ED...: 100%|██████████| 11889/11889 [00:09<00:00, 1242.24it/s]\n",
      "Processing TL_인공물_EE...: 100%|██████████| 3043/3043 [00:02<00:00, 1210.72it/s]\n",
      "Processing TL_자연_NA...: 100%|██████████| 545/545 [00:00<00:00, 1043.66it/s]\n",
      "Processing TL_생명_LA...: 100%|██████████| 1490/1490 [00:01<00:00, 1168.90it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(\"data\", \"01-1.정식개방데이터\", \"Training\", \"02.라벨링데이터\")\n",
    "eval_dataset = []\n",
    "\n",
    "dir_list = os.listdir(data_dir)\n",
    "for dir_name in dir_list:\n",
    "    if dir_name == \".DS_Store\" or dir_name.endswith(\".zip\"): continue\n",
    "    file_list = os.listdir(os.path.join(data_dir, dir_name))\n",
    "    for file_name in tqdm(file_list, desc=f\"Processing {dir_name}...\"):\n",
    "        df = pd.read_json(os.path.join(data_dir, dir_name, file_name))\n",
    "        for data in df.loc['context_info', 'dataset']:\n",
    "            context = data['context']\n",
    "            terminology = [word['word'] for word in data['terminology']]\n",
    "\n",
    "            eval_dataset.append(\n",
    "                {\n",
    "                    'context' : context,\n",
    "                    'terminology' : terminology\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd1bb058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96049"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a1b5635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': '<h1>I. 서 론</h1> <p>전자공학의 발달과 자동화.무인화 추세에 따라 철도차량에도 많은 센서와 액추에이터가 장착되었고 이들에 대한 원격 정보 전달과 제어가 필요하게 되었다. 따라서 중앙 혹은 각 차량에 있는 처리장치와 이들 센서및 액추에이터간의 연결을 위해 다양한 통신 방식의 연결이 구현되었다. 이러한 통신 방식에는 RS-422,RS-485 등 UART 통신과 CAN, MVB 등이 있다. 그러나 이렇게 다양한 통신 방식의 혼용은 데이터 전송의 효율성을 저하시키고 배선의 복잡성을 증가시킬 뿐만아니라 그 성능 또한 최신의 네트워크 기술에 비해 부족하여 통일된 방식으로 네트워크를 구성할 필요성을 대두시켰다.</p> <p>통합 네트워크의 후보로 가장 적합하다고 여겨지는것은 이더넷이며, 먼저 자동차 분야에서 이더넷으로 통합하기 위한 연구가 시도되었다. 자동차 또한 다양한센서 및 액추에이터가 부착되므로 이들을 네트워크로 구성하고 효율성과 안전성을 고려하여 적절한 시간 내에 감지하고 제어가 될 수 있도록 하는 연구가 많이 이루어졌으며 이에 대한 연구주제로는 네트워크 구조,성능, 실시간성 등이 있다.</p> <p>철도 차량의 경우 자동차와는 구별되는 특징을 가지며 이를 고려하여 네트워크 구성을 적용해야 한다. 철도 차량의 경우 여러 대의 차량이 일렬로 연결되는 구조를 가지므로 네트워크 구성 상 차량 내 연결과 차량간 연결을 구분해야 한다. 특히 차량 간 연결의 경우 연결기(coupler)를 사용하여 이 안의 홀을 통해 케이블로 연결하거나 그림 1과 같이 케이블을 밖으로 빼서 차량사이를 연결하여야 한다. 따라서 제작 공정 및 유지보수 등을 위해 최대로 연결될 수 있는 케이블의 수는 제한된다.</p> <p>철도차량용 네트워크 토폴로지로는 기존의 링, 데이지체인, 스타, 버스 등을 사용할 수 있으며 각각 차량 내부 연결과 차량 간 연결로 나누어서 구성할 수 있다. 그림 2에 차량 내 연결과 차량 간 연결의 대표적인토폴로지를 나타내었다. 그림 2에서 확인할 수 있듯이차량 간 연결의 여러 토폴로지 중 가장 안정적인 속도성능을 보이는 것은 스타 토폴로지이며 케이블 수를 절감할 수 있는 것은 데이지체인 토폴로지 이다. 그러나 스타 토폴로지의 경우 차량 간 연결에 케이블 수가 많아진 다는 단점이 있고 데이지체인의 경우 멀리 떨어진 차량 간 통신에서는 거치는 노드의 수가 증가하여 지연시간이 커진다는 단점이 있다. 따라서, 이러한 두 토폴로지의 장단점을 절충하여 차량 간 연결에서 케이블 수를 절감하고 지연 시간 증가 문제를 완화하기 위해 하이브리드 토폴로지가 제안되었다[8].</p> <p>하이브리드 토폴로지에서는 각 차량을 적절한 수의그룹으로 묶고 그룹 내에서는 스타 토폴로지, 그룹 간은 데이지체인 토폴로지를 사용한다. 이를 통해 스타토폴로지에서 발생하는 문제점인 많은 케이블과 통신의중앙 집중에 따른 큰 위험 부담을 절감하면서 데이지체인 보다는 빠른 전송 속도를 나타낼 수 있다. 하이브리드 토폴로지는 두 가지 토폴로지를 절충하는 것이므로 각각의 장점을 잘 활용할 수 있도록 그룹 내 차량의 수를 적절히 선정하는 것이 중요하다.</p> <p>각 장치별 데이터 패킷의 생성 주기와 크기, 그리고허용되는 최대 지연시간에 대한 정보가 주어졌을 때에는 이에 대한 값을 설정하고 시뮬레이션을 실행함으로써 네트워크의 최적화를 수행할 수 있다. 그러나 이러한 절차는 모든 장치가 선정되고 각 장치간의 데이터교환 구조가 정립된 후에야 정확한 값을 알 수 있다는단점이 있다. 그렇지 않을 경우 데이터에 대한 크기 및생성율에 대한 사항을 대략적으로 가정하고 시뮬레이션을 통해 구한다. 그런데 시스템 설계 초기 단계에서는이에 대한 가정 또한 여의치 않으며 향후 장치 및 데이터의 추가 등이 예정되어 있어 초기 가정이 유효하다고볼 수 없는 경우가 많다. 따라서, 이를 고려할 때 기본적인 가정에서의 최적화된 토폴로지를 도출할 필요가있다.</p> <p>본 논문에서는 철도차량에서 차량 별로 데이터 생성크기와 생성 주기가 동일하다는 가정 하에 최적의 하이브리드 네트워크 토폴로지를 구하는 것을 목적으로 한다. 이를 위해 차량 간 연결에서의 최대 케이블 수와 전송 시 평균 경유 노드(스위칭허브)에 대하여 각각 가중치를 별도로 두고 가중치 별로 전체 차량 수에 따른 최적의 그룹 내 차량의 수를 도출한다.</p> <p>이를 위한 본 논문의 구성은 다음과 같다. 먼저 II 장에서는 하이브리드 토폴로지에서 그룹 내 최적의 차량수를 구하는 수식을 도출하고 이에 대한 해를 구하며,III 장에서는 차량의 수와 가중치를 변화시켜가면서 시뮬레이션을 수행함으로써 II 장에서 도출한 식과 해가 적절함을 검증한다. 마지막으로 IV 장에서는 결론과 추가로 연구할 바를 제시한다.</p>',\n",
       " 'terminology': ['CAN',\n",
       "  'MVB',\n",
       "  'UART',\n",
       "  'coupler',\n",
       "  '가중치',\n",
       "  '경유 노드',\n",
       "  '네트워크',\n",
       "  '네트워크 토폴로지',\n",
       "  '노드',\n",
       "  '데이지체인',\n",
       "  '데이터 패킷',\n",
       "  '생성 주기',\n",
       "  '시뮬레이션',\n",
       "  '시스템 설계',\n",
       "  '액추에이터',\n",
       "  '연결기',\n",
       "  '전송',\n",
       "  '전자공학',\n",
       "  '지연 시간',\n",
       "  '토폴',\n",
       "  '토폴로지',\n",
       "  '패킷',\n",
       "  '하이브리드 네트워크']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5753d5ab",
   "metadata": {},
   "source": [
    "## Implement Keyword Extract functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fe6f39",
   "metadata": {},
   "source": [
    "### 1. TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7f8be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRankKeywordExtractor:\n",
    "    def __init__(self, text:str, stopwords:list[str]=None):\n",
    "        self.text = text\n",
    "\n",
    "        # define tagger\n",
    "        tagger = Okt()\n",
    "\n",
    "        # make vocab list\n",
    "        if stopwords:\n",
    "            # get nouns in given text\n",
    "            nouns = tagger.nouns(self.text)\n",
    "            # remove stopwords in nouns\n",
    "            self.vocab = list(set([noun for noun in nouns if noun not in stopwords]))\n",
    "        else:\n",
    "            # set raw noun list as vocab list\n",
    "            self.vocab = tagger.nouns(self.text)\n",
    "        \n",
    "        self.vocab_to_idx = {word:idx for idx, word in enumerate(self.vocab)}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "    \n",
    "    def get_coappear_graph(self, window:int):\n",
    "        self.graph = np.zeros((self.vocab_size, self.vocab_size))\n",
    "        words = self.text.split()\n",
    "        for i, word in enumerate(words):\n",
    "            if word in self.vocab:\n",
    "                for j in range(max(i-window, 0), min(i+window+1, len(words))):\n",
    "                    if (i != j) and words[j] in self.vocab:\n",
    "                        idx1, idx2 = self.vocab_to_idx[word], self.vocab_to_idx[words[j]]\n",
    "                        self.graph[idx1][idx2] += 1\n",
    "    \n",
    "    def get_pagerank_score(self, d_factor:int, max_iter:int):\n",
    "        A = normalize(self.graph, axis=0, norm='l1')\n",
    "        self.R = np.ones((self.vocab_size, 1))\n",
    "        bias = (1-d_factor) * np.ones((self.vocab_size,1))\n",
    "        for _ in range(max_iter):\n",
    "            self.R = d_factor * np.dot(A, self.R) + bias\n",
    "    \n",
    "    def get_top_n(self, top_n:int):\n",
    "        idxs = self.R.flatten().argsort()[-top_n:][::-1]\n",
    "        return [self.vocab[idx] for idx in idxs]\n",
    "    \n",
    "    def extract(self, window:int=5, d_factor:int=0.85, max_iter:int=30, top_n:int=10):\n",
    "        if len(self.vocab) == 0: return []\n",
    "        self.get_coappear_graph(window=window)\n",
    "        self.get_pagerank_score(d_factor=d_factor, max_iter=max_iter)\n",
    "        return self.get_top_n(top_n=top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dff745f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(set([\"종\", \"그\", \"및\", \"등\", \"각\", \"개\", \"를\", \"사\", \"위\", \"전\", \"용\", \"처\", \"통해\", \"기술\", \"부문\", \"경쟁력\", \"제품\", \"사업\",\n",
    "             \"시장\", \"판매\", \"지속\", \"기업\", \"생산\", \"확대\", \"기업\", \"당사\", \"차별\", \"솔루션\", \"부품\", \"개발\", \"적용\", \"공정\", \"한편\", \"업체\",\n",
    "             \"운영\", \"선두\", \"전장\", \"또한\", \"추진\", \"구성\", \"응용\", \"일반\", \"영위\", \"해외\", \"경영\", \"본사\", \"지역\", \"주요\", \"다음\", \"삼성\",\n",
    "             \"협업\", \"서비스\", \"선단\", \"특화\", \"심화\", \"제품군\", \"설계\", \"대형\", \"세계\", \"소비자\", \"라인업\", \"혁신\", \"차세대\", \"공급\", \"글로벌\", \"고화질\",\n",
    "             \"경쟁\", \"강화\", \"더블\", \"경험\", \"율\", \"의\", \"고하\", \"뿐\", \"로서\", \"탑재\", \"자체\", \"원가\"]))\n",
    "\n",
    "# textrank_extractor = TextRankKeywordExtractor(text, stopwords=stopwords)\n",
    "# textrank_extractor.extract(\n",
    "#     window=3,\n",
    "#     max_iter=30\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeccd427",
   "metadata": {},
   "source": [
    "### 2. Embedding Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf8f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIEmbeddingBasedExtractor:\n",
    "    def __init__(self, text:str, stopwords:list=None):\n",
    "        okt = Okt()\n",
    "        nouns = okt.nouns(text)\n",
    "        self.text = text\n",
    "\n",
    "        if stopwords: self.candidates = list(set([noun for noun in nouns if noun not in stopwords]))\n",
    "        else: self.candidates = list(set(nouns))\n",
    "\n",
    "        self.embedding_model = OpenAIEmbeddings()\n",
    "    \n",
    "    def embed(self):\n",
    "        self.embeddings = self.embedding_model.embed_documents(self.candidates)\n",
    "        self.whole_text_embedding = self.embedding_model.embed_query(self.text)\n",
    "      \n",
    "    def extract(self, top_n=7):\n",
    "        cos_sim_score = []\n",
    "        if len(self.candidates) == 0: return []\n",
    "        self.embed()\n",
    "\n",
    "        for embedding_vector in self.embeddings:\n",
    "            cos_sim_score.append(cosine_similarity([embedding_vector], [self.whole_text_embedding])[0][0])\n",
    "\n",
    "        cos_sim_score_df = pd.DataFrame([cos_sim_score], columns=self.candidates)\n",
    "\n",
    "        def get_top_words(row:pd.Series, top_n:int=top_n):\n",
    "            return row.sort_values(ascending=False).head(top_n).index.tolist()\n",
    "\n",
    "        return cos_sim_score_df.apply(get_top_words, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e5b6ff",
   "metadata": {},
   "source": [
    "### 3. KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e282ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyBERTExtractor:\n",
    "    def __init__(self, text, model=None, stopwords=None):\n",
    "        if not model: model = BertModel.from_pretrained('skt/kobert-base-v1')\n",
    "        self.okt = Okt()\n",
    "        self.kw_model = KeyBERT(model)\n",
    "        self.text = text\n",
    "        self.stopwords = stopwords\n",
    "    \n",
    "    def extract(self, top_n=10, ngram_range=(1,1), use_mmr=False, use_msum=False):\n",
    "        nouns = self.okt.nouns(self.text)\n",
    "        if len([noun for noun in nouns if noun not in self.stopwords]) == 0: return []\n",
    "        if use_mmr and use_msum :\n",
    "            keywords = self.kw_model.extract_keywords(\n",
    "                ' '.join(nouns), \n",
    "                keyphrase_ngram_range=ngram_range, \n",
    "                stop_words=self.stopwords, \n",
    "                top_n=top_n,\n",
    "                use_mmr=use_mmr,\n",
    "                diversity=0.5,\n",
    "                use_maxsum=use_msum,\n",
    "                nr_candidates=20\n",
    "            )\n",
    "        elif use_mmr:\n",
    "            keywords = self.kw_model.extract_keywords(\n",
    "                ' '.join(nouns), \n",
    "                keyphrase_ngram_range=ngram_range, \n",
    "                stop_words=self.stopwords, \n",
    "                top_n=top_n,\n",
    "                use_mmr=use_mmr,\n",
    "                diversity=0.5,\n",
    "            )\n",
    "        elif use_msum:\n",
    "            keywords = self.kw_model.extract_keywords(\n",
    "                ' '.join(nouns), \n",
    "                keyphrase_ngram_range=ngram_range, \n",
    "                stop_words=self.stopwords, \n",
    "                top_n=top_n,\n",
    "                use_maxsum=use_msum,\n",
    "                nr_candidates=20\n",
    "            )\n",
    "        else:\n",
    "            keywords = self.kw_model.extract_keywords(\n",
    "                ' '.join(nouns), \n",
    "                keyphrase_ngram_range=ngram_range, \n",
    "                stop_words=self.stopwords, \n",
    "                top_n=top_n,\n",
    "            )\n",
    "        \n",
    "        return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59606ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords = list(set([\"종\", \"그\", \"및\", \"등\", \"각\", \"개\", \"를\", \"사\", \"위\", \"전\", \"용\", \"처\", \"통해\", \"기술\", \"부문\", \"경쟁력\", \"제품\", \"사업\",\n",
    "#              \"시장\", \"판매\", \"지속\", \"기업\", \"생산\", \"확대\", \"기업\", \"당사\", \"차별\", \"솔루션\", \"부품\", \"개발\", \"적용\", \"공정\", \"한편\", \"업체\",\n",
    "#              \"운영\", \"선두\", \"전장\", \"또한\", \"추진\", \"구성\", \"응용\", \"일반\", \"영위\", \"해외\", \"경영\", \"본사\", \"지역\", \"주요\", \"다음\", \"삼성\",\n",
    "#              \"협업\", \"서비스\", \"선단\", \"특화\", \"심화\", \"제품군\", \"설계\", \"대형\", \"세계\", \"소비자\", \"라인업\", \"혁신\", \"차세대\", \"공급\", \"글로벌\", \"고화질\",\n",
    "#              \"경쟁\", \"강화\", \"더블\", \"경험\", \"율\", \"의\", \"고하\", \"뿐\", \"로서\", \"탑재\", \"자체\", \"원가\"]))\n",
    "\n",
    "# model = BertModel.from_pretrained('skt/kobert-base-v1')\n",
    "\n",
    "# keybert_extractor = KeyBERTExtractor(text=text, model=model, stopwords=stopwords)\n",
    "# keywords = keybert_extractor.extract(\n",
    "#     top_n=10,\n",
    "#     use_mmr=True,\n",
    "#     use_msum=True\n",
    "# )\n",
    "\n",
    "# print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d52427",
   "metadata": {},
   "source": [
    "### 4. LLM Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "482feeb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x33d0f2da0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class KeyWordsModel(BaseModel):\n",
    "    keywords: Annotated[list[str], \"텍스트로 부터 추출한 키워드를 담는 리스트\"]\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o',\n",
    "    temperature=0\n",
    ")\n",
    "structured_llm = llm.with_structured_output(KeyWordsModel)\n",
    "\n",
    "# Define State\n",
    "class InputState(TypedDict):\n",
    "    context: str\n",
    "\n",
    "class OutputState(TypedDict):\n",
    "    keywords: list[str]\n",
    "\n",
    "class GraphState(InputState, OutputState):\n",
    "    pass\n",
    "\n",
    "# Define Nodes\n",
    "def keyword_extraction_node(state: InputState):\n",
    "    context = state['context']\n",
    "\n",
    "    system_message_content = \"\"\"\n",
    "    당신은 전문적인 기업 트렌드 분석가 입니다.\n",
    "    당신의 임무는 주어진 텍스트에서 기업 분석을 위한 주요 키워드를 추출하는 것입니다.\n",
    "    다음의 지침을 준수하며 기업의 트렌드 분석이 가능하도록 키워드를 30개 추출하세요.\n",
    "\n",
    "    <지침>\n",
    "    1. '사업', '선두주자'와 같이 해당 기업에 대해 설명할 수 없는 너무 일반적인 키워드는 제외하세요.\n",
    "    2. '~부문' 과 같이 특정 분야를 총괄하는 키워드는 제외하고, 기업에 대해 분석 가능한 직접적인 키워드를 선정하세요.\n",
    "    </지침>\n",
    "    \"\"\"\n",
    "\n",
    "    human_message_content = f\"\"\"\n",
    "    다음의 텍스트에서 해당 기업의 트렌드 분석을 위한 키워드를 추출해주세요.\n",
    "\n",
    "    텍스트:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "\n",
    "    system_message = SystemMessage(content=system_message_content)\n",
    "    human_message = HumanMessage(content=human_message_content)\n",
    "\n",
    "    keyword_list = structured_llm.invoke([system_message, human_message])\n",
    "\n",
    "    return {\n",
    "        \"keywords\" : keyword_list.keywords\n",
    "    }\n",
    "\n",
    "\n",
    "# Define Graph Builder\n",
    "workflow = StateGraph(\n",
    "    GraphState,\n",
    "    input=InputState,\n",
    "    output=OutputState\n",
    ")\n",
    "\n",
    "# add nodes\n",
    "workflow.add_node(\"extract_keywords\", keyword_extraction_node)\n",
    "\n",
    "# add edges\n",
    "workflow.add_edge(START, \"extract_keywords\")\n",
    "workflow.add_edge(\"extract_keywords\", END)\n",
    "\n",
    "# Compile Graph\n",
    "app = workflow.compile()\n",
    "\n",
    "app    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bf2075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.invoke({\"context\" : text})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18796d16",
   "metadata": {},
   "source": [
    "## Construct Evaluate Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b25e0e",
   "metadata": {},
   "source": [
    "### Critic Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be0e5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_keyword_metrics(ground_truth, predicted):\n",
    "    gt_set = set(ground_truth)\n",
    "    pred_set = set(predicted)\n",
    "    \n",
    "    # True Positive: 예측한 키워드 중 정답에 포함된 것\n",
    "    tp = len(gt_set.intersection(pred_set))\n",
    "    # False Positive: 예측한 키워드 중 정답에 포함되지 않은 것\n",
    "    fp = len(pred_set - gt_set)\n",
    "    # False Negative: 정답 키워드 중 예측하지 못한 것\n",
    "    fn = len(gt_set - pred_set)\n",
    "\n",
    "    # Precision\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    # Recall\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    # F1 Score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'ground_truth_count': len(gt_set),\n",
    "        'predicted_count': len(pred_set)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e0d565",
   "metadata": {},
   "source": [
    "### TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fcaec52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TextRank Evaluating... : 100%|██████████| 100/100 [00:02<00:00, 33.39it/s]\n"
     ]
    }
   ],
   "source": [
    "stopwords = list(set([\"종\", \"그\", \"및\", \"등\", \"각\", \"개\", \"를\", \"사\", \"위\", \"전\", \"용\", \"처\", \"통해\", \"기술\", \"부문\", \"경쟁력\", \"제품\", \"사업\",\n",
    "             \"시장\", \"판매\", \"지속\", \"기업\", \"생산\", \"확대\", \"기업\", \"당사\", \"차별\", \"솔루션\", \"부품\", \"개발\", \"적용\", \"공정\", \"한편\", \"업체\",\n",
    "             \"운영\", \"선두\", \"전장\", \"또한\", \"추진\", \"구성\", \"응용\", \"일반\", \"영위\", \"해외\", \"경영\", \"본사\", \"지역\", \"주요\", \"다음\", \"삼성\",\n",
    "             \"협업\", \"서비스\", \"선단\", \"특화\", \"심화\", \"제품군\", \"설계\", \"대형\", \"세계\", \"소비자\", \"라인업\", \"혁신\", \"차세대\", \"공급\", \"글로벌\", \"고화질\",\n",
    "             \"경쟁\", \"강화\", \"더블\", \"경험\", \"율\", \"의\", \"고하\", \"뿐\", \"로서\", \"탑재\", \"자체\", \"원가\", \"간\", \"수\", \"경우\", \"내\", \"따라서\", \"대한\"]))\n",
    "\n",
    "eval_results = []\n",
    "for gt in tqdm(eval_dataset[:100], desc=\"TextRank Evaluating... : \"):\n",
    "    text = gt['context']\n",
    "    gt_keywords = gt['terminology']\n",
    "\n",
    "    textrank_extractor = TextRankKeywordExtractor(text, stopwords=stopwords)\n",
    "    pred_keywords = textrank_extractor.extract(\n",
    "        window=3,\n",
    "        max_iter=30,\n",
    "        top_n=30\n",
    "    )\n",
    "\n",
    "    eval_results.append(calculate_keyword_metrics(\n",
    "        ground_truth=gt_keywords,\n",
    "        predicted=pred_keywords\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1627b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Avg Precision : 0.10423194192377493\n",
      " Avg recall : 0.12393775441033852\n",
      " Avg f1 score : 0.10323048807776919\n",
      " Avg ground truth count : 32.19\n",
      " Avg predicted count : 29.76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_f1 = 0\n",
    "total_gt_cnt = 0\n",
    "total_pred_cnt = 0\n",
    "eval_amount = len(eval_results)\n",
    "\n",
    "for eval in eval_results:\n",
    "    total_precision += eval['precision']\n",
    "    total_recall += eval['recall']\n",
    "    total_f1 += eval['f1_score']\n",
    "    total_gt_cnt += eval['ground_truth_count']\n",
    "    total_pred_cnt += eval['predicted_count']\n",
    "\n",
    "print(\n",
    "    f\" Avg Precision : {total_precision / eval_amount}\\n\",\n",
    "    f\"Avg recall : {total_recall / eval_amount}\\n\",\n",
    "    f\"Avg f1 score : {total_f1 / eval_amount}\\n\",\n",
    "    f\"Avg ground truth count : {total_gt_cnt / eval_amount}\\n\",\n",
    "    f\"Avg predicted count : {total_pred_cnt / eval_amount}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f13220",
   "metadata": {},
   "source": [
    "### Embedding Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b9895a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Based Evaluating... : 100%|██████████| 100/100 [03:39<00:00,  2.20s/it]\n"
     ]
    }
   ],
   "source": [
    "stopwords = list(set([\"종\", \"그\", \"및\", \"등\", \"각\", \"개\", \"를\", \"사\", \"위\", \"전\", \"용\", \"처\", \"통해\", \"기술\", \"부문\", \"경쟁력\", \"제품\", \"사업\",\n",
    "             \"시장\", \"판매\", \"지속\", \"기업\", \"생산\", \"확대\", \"기업\", \"당사\", \"차별\", \"솔루션\", \"부품\", \"개발\", \"적용\", \"공정\", \"한편\", \"업체\",\n",
    "             \"운영\", \"선두\", \"전장\", \"또한\", \"추진\", \"구성\", \"응용\", \"일반\", \"영위\", \"해외\", \"경영\", \"본사\", \"지역\", \"주요\", \"다음\", \"삼성\",\n",
    "             \"협업\", \"서비스\", \"선단\", \"특화\", \"심화\", \"제품군\", \"설계\", \"대형\", \"세계\", \"소비자\", \"라인업\", \"혁신\", \"차세대\", \"공급\", \"글로벌\", \"고화질\",\n",
    "             \"경쟁\", \"강화\", \"더블\", \"경험\", \"율\", \"의\", \"고하\", \"뿐\", \"로서\", \"탑재\", \"자체\", \"원가\", \"간\", \"수\", \"경우\", \"내\", \"따라서\", \"대한\"]))\n",
    "\n",
    "eval_results = []\n",
    "for gt in tqdm(eval_dataset[:100], desc=\"Embedding Based Evaluating... : \"):\n",
    "    text = gt['context']\n",
    "    gt_keywords = gt['terminology']\n",
    "\n",
    "    embeddingbased_extractor = OpenAIEmbeddingBasedExtractor(text, stopwords=stopwords)\n",
    "    pred_keywords = embeddingbased_extractor.extract(\n",
    "        top_n=30\n",
    "    )\n",
    "\n",
    "    if len(pred_keywords) == 0:\n",
    "        eval_results.append(calculate_keyword_metrics(\n",
    "            ground_truth=gt_keywords,\n",
    "            predicted=pred_keywords\n",
    "        ))\n",
    "    else:\n",
    "        eval_results.append(calculate_keyword_metrics(\n",
    "            ground_truth=gt_keywords,\n",
    "            predicted=pred_keywords[0]\n",
    "        ))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8189365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Avg Precision : 0.14589860859044146\n",
      " Avg recall : 0.1681523442769958\n",
      " Avg f1 score : 0.14262896542578957\n",
      " Avg ground truth count : 32.19\n",
      " Avg predicted count : 29.76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_f1 = 0\n",
    "total_gt_cnt = 0\n",
    "total_pred_cnt = 0\n",
    "eval_amount = len(eval_results)\n",
    "\n",
    "for eval in eval_results:\n",
    "    total_precision += eval['precision']\n",
    "    total_recall += eval['recall']\n",
    "    total_f1 += eval['f1_score']\n",
    "    total_gt_cnt += eval['ground_truth_count']\n",
    "    total_pred_cnt += eval['predicted_count']\n",
    "\n",
    "print(\n",
    "    f\" Avg Precision : {total_precision / eval_amount}\\n\",\n",
    "    f\"Avg recall : {total_recall / eval_amount}\\n\",\n",
    "    f\"Avg f1 score : {total_f1 / eval_amount}\\n\",\n",
    "    f\"Avg ground truth count : {total_gt_cnt / eval_amount}\\n\",\n",
    "    f\"Avg predicted count : {total_pred_cnt / eval_amount}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be682b8",
   "metadata": {},
   "source": [
    "### KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b5de03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyBERT Evaluating... :  16%|█▌        | 16/100 [01:06<05:39,  4.04s/it]HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "KeyBERT Evaluating... :  17%|█▋        | 17/100 [01:33<15:01, 10.86s/it]HTTP Error 429 thrown while requesting HEAD https://huggingface.co/skt/kobert-base-v1/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/skt/kobert-base-v1/resolve/main/config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "KeyBERT Evaluating... :  34%|███▍      | 34/100 [02:46<04:35,  4.17s/it]HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "KeyBERT Evaluating... :  52%|█████▏    | 52/100 [04:23<03:14,  4.05s/it]HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/tokenizer_config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "KeyBERT Evaluating... :  69%|██████▉   | 69/100 [05:59<02:07,  4.10s/it]HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/config_sentence_transformers.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/config_sentence_transformers.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/config_sentence_transformers.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/config_sentence_transformers.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/config_sentence_transformers.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/config_sentence_transformers.json\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/./README.md\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/./README.md\n",
      "Retrying in 2s [Retry 2/5].\n",
      "KeyBERT Evaluating... :  86%|████████▌ | 86/100 [07:34<00:56,  4.05s/it]HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/modules.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/modules.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/modules.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/modules.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/modules.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/modules.json\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/./config_sentence_transformers.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/./config_sentence_transformers.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "KeyBERT Evaluating... : 100%|██████████| 100/100 [08:57<00:00,  5.37s/it]\n"
     ]
    }
   ],
   "source": [
    "stopwords = list(set([\"종\", \"그\", \"및\", \"등\", \"각\", \"개\", \"를\", \"사\", \"위\", \"전\", \"용\", \"처\", \"통해\", \"기술\", \"부문\", \"경쟁력\", \"제품\", \"사업\",\n",
    "             \"시장\", \"판매\", \"지속\", \"기업\", \"생산\", \"확대\", \"기업\", \"당사\", \"차별\", \"솔루션\", \"부품\", \"개발\", \"적용\", \"공정\", \"한편\", \"업체\",\n",
    "             \"운영\", \"선두\", \"전장\", \"또한\", \"추진\", \"구성\", \"응용\", \"일반\", \"영위\", \"해외\", \"경영\", \"본사\", \"지역\", \"주요\", \"다음\", \"삼성\",\n",
    "             \"협업\", \"서비스\", \"선단\", \"특화\", \"심화\", \"제품군\", \"설계\", \"대형\", \"세계\", \"소비자\", \"라인업\", \"혁신\", \"차세대\", \"공급\", \"글로벌\", \"고화질\",\n",
    "             \"경쟁\", \"강화\", \"더블\", \"경험\", \"율\", \"의\", \"고하\", \"뿐\", \"로서\", \"탑재\", \"자체\", \"원가\", \"간\", \"수\", \"경우\", \"내\", \"따라서\", \"대한\"]))\n",
    "\n",
    "eval_results = []\n",
    "for gt in tqdm(eval_dataset[:100], desc=\"KeyBERT Evaluating... : \"):\n",
    "    text = gt['context']\n",
    "    gt_keywords = gt['terminology']\n",
    "\n",
    "    model = BertModel.from_pretrained('skt/kobert-base-v1')\n",
    "    keybert_extractor = KeyBERTExtractor(text, model=model, stopwords=stopwords)\n",
    "    pred_keywords = keybert_extractor.extract(\n",
    "        top_n=30\n",
    "    )\n",
    "\n",
    "    if len(pred_keywords) == 0:\n",
    "        eval_results.append(calculate_keyword_metrics(\n",
    "            ground_truth=gt_keywords,\n",
    "            predicted=pred_keywords\n",
    "        ))\n",
    "    else:\n",
    "        pred_keywords = [word for word, score in pred_keywords]\n",
    "        eval_results.append(calculate_keyword_metrics(\n",
    "            ground_truth=gt_keywords,\n",
    "            predicted=pred_keywords\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14864dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Avg Precision : 0.13720330394243427\n",
      " Avg recall : 0.1555867222443692\n",
      " Avg f1 score : 0.13414991838596302\n",
      " Avg ground truth count : 32.19\n",
      " Avg predicted count : 29.29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_f1 = 0\n",
    "total_gt_cnt = 0\n",
    "total_pred_cnt = 0\n",
    "eval_amount = len(eval_results)\n",
    "\n",
    "for eval in eval_results:\n",
    "    total_precision += eval['precision']\n",
    "    total_recall += eval['recall']\n",
    "    total_f1 += eval['f1_score']\n",
    "    total_gt_cnt += eval['ground_truth_count']\n",
    "    total_pred_cnt += eval['predicted_count']\n",
    "\n",
    "print(\n",
    "    f\" Avg Precision : {total_precision / eval_amount}\\n\",\n",
    "    f\"Avg recall : {total_recall / eval_amount}\\n\",\n",
    "    f\"Avg f1 score : {total_f1 / eval_amount}\\n\",\n",
    "    f\"Avg ground truth count : {total_gt_cnt / eval_amount}\\n\",\n",
    "    f\"Avg predicted count : {total_pred_cnt / eval_amount}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2271876f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyBERT Evaluating... :  16%|█▌        | 16/100 [01:06<05:52,  4.20s/it]HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/config.json\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/tokenizer_config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "KeyBERT Evaluating... :  33%|███▎      | 33/100 [02:42<04:33,  4.08s/it]HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/README.md\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/README.md\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/README.md\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/README.md\n",
      "Retrying in 8s [Retry 4/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/README.md\n",
      "Retrying in 8s [Retry 5/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/README.md\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/./modules.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "KeyBERT Evaluating... :  49%|████▉     | 49/100 [04:14<03:40,  4.32s/it]HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "KeyBERT Evaluating... :  50%|█████     | 50/100 [04:42<09:18, 11.17s/it]HTTP Error 429 thrown while requesting HEAD https://huggingface.co/skt/kobert-base-v1/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/skt/kobert-base-v1/resolve/main/config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "KeyBERT Evaluating... :  66%|██████▌   | 66/100 [05:50<02:20,  4.14s/it]HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/tokenizer_config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/tokenizer_config.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/tokenizer_config.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/tokenizer_config.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/tokenizer_config.json\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/1_Pooling/config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "KeyBERT Evaluating... :  83%|████████▎ | 83/100 [07:26<01:10,  4.15s/it]HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/config.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/config.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/config.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/86741b4e3f5cb7765a600d3a3d55a0f6a6cb443d/config.json\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 429 thrown while requesting HEAD https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/tokenizer_config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "KeyBERT Evaluating... : 100%|██████████| 100/100 [09:02<00:00,  5.42s/it]\n"
     ]
    }
   ],
   "source": [
    "stopwords = list(set([\"종\", \"그\", \"및\", \"등\", \"각\", \"개\", \"를\", \"사\", \"위\", \"전\", \"용\", \"처\", \"통해\", \"기술\", \"부문\", \"경쟁력\", \"제품\", \"사업\",\n",
    "             \"시장\", \"판매\", \"지속\", \"기업\", \"생산\", \"확대\", \"기업\", \"당사\", \"차별\", \"솔루션\", \"부품\", \"개발\", \"적용\", \"공정\", \"한편\", \"업체\",\n",
    "             \"운영\", \"선두\", \"전장\", \"또한\", \"추진\", \"구성\", \"응용\", \"일반\", \"영위\", \"해외\", \"경영\", \"본사\", \"지역\", \"주요\", \"다음\", \"삼성\",\n",
    "             \"협업\", \"서비스\", \"선단\", \"특화\", \"심화\", \"제품군\", \"설계\", \"대형\", \"세계\", \"소비자\", \"라인업\", \"혁신\", \"차세대\", \"공급\", \"글로벌\", \"고화질\",\n",
    "             \"경쟁\", \"강화\", \"더블\", \"경험\", \"율\", \"의\", \"고하\", \"뿐\", \"로서\", \"탑재\", \"자체\", \"원가\", \"간\", \"수\", \"경우\", \"내\", \"따라서\", \"대한\"]))\n",
    "\n",
    "eval_results = []\n",
    "for gt in tqdm(eval_dataset[:100], desc=\"KeyBERT Evaluating... : \"):\n",
    "    text = gt['context']\n",
    "    gt_keywords = gt['terminology']\n",
    "\n",
    "    model = BertModel.from_pretrained('skt/kobert-base-v1')\n",
    "    keybert_extractor = KeyBERTExtractor(text, model=model, stopwords=stopwords)\n",
    "    pred_keywords = keybert_extractor.extract(\n",
    "        top_n=30,\n",
    "        use_mmr=True,\n",
    "        use_msum=True\n",
    "    )\n",
    "\n",
    "    if len(pred_keywords) == 0:\n",
    "        eval_results.append(calculate_keyword_metrics(\n",
    "            ground_truth=gt_keywords,\n",
    "            predicted=pred_keywords\n",
    "        ))\n",
    "    else:\n",
    "        pred_keywords = [word for word, score in pred_keywords]\n",
    "        eval_results.append(calculate_keyword_metrics(\n",
    "            ground_truth=gt_keywords,\n",
    "            predicted=pred_keywords\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cdca00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Avg Precision : 0.12286997060910097\n",
      " Avg recall : 0.1424349653012377\n",
      " Avg f1 score : 0.12057443446260702\n",
      " Avg ground truth count : 32.19\n",
      " Avg predicted count : 29.29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_f1 = 0\n",
    "total_gt_cnt = 0\n",
    "total_pred_cnt = 0\n",
    "eval_amount = len(eval_results)\n",
    "\n",
    "for eval in eval_results:\n",
    "    total_precision += eval['precision']\n",
    "    total_recall += eval['recall']\n",
    "    total_f1 += eval['f1_score']\n",
    "    total_gt_cnt += eval['ground_truth_count']\n",
    "    total_pred_cnt += eval['predicted_count']\n",
    "\n",
    "print(\n",
    "    f\" Avg Precision : {total_precision / eval_amount}\\n\",\n",
    "    f\"Avg recall : {total_recall / eval_amount}\\n\",\n",
    "    f\"Avg f1 score : {total_f1 / eval_amount}\\n\",\n",
    "    f\"Avg ground truth count : {total_gt_cnt / eval_amount}\\n\",\n",
    "    f\"Avg predicted count : {total_pred_cnt / eval_amount}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88b41bb",
   "metadata": {},
   "source": [
    "### LLM Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10c3f049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Based Evaluating... : 100%|██████████| 100/100 [06:53<00:00,  4.13s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_results = []\n",
    "for gt in tqdm(eval_dataset[:100], desc=\"LLM Based Evaluating... : \"):\n",
    "    text = gt['context']\n",
    "    gt_keywords = gt['terminology']\n",
    "\n",
    "    pred_keywords = app.invoke({\"context\" : text})\n",
    "\n",
    "    eval_results.append(calculate_keyword_metrics(\n",
    "        ground_truth=gt_keywords,\n",
    "        predicted=pred_keywords['keywords']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f41f6973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Avg Precision : 0.3088381535038931\n",
      " Avg recall : 0.33853279721375207\n",
      " Avg f1 score : 0.2964641477502071\n",
      " Avg ground truth count : 32.19\n",
      " Avg predicted count : 29.91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_f1 = 0\n",
    "total_gt_cnt = 0\n",
    "total_pred_cnt = 0\n",
    "eval_amount = len(eval_results)\n",
    "\n",
    "for eval in eval_results:\n",
    "    total_precision += eval['precision']\n",
    "    total_recall += eval['recall']\n",
    "    total_f1 += eval['f1_score']\n",
    "    total_gt_cnt += eval['ground_truth_count']\n",
    "    total_pred_cnt += eval['predicted_count']\n",
    "\n",
    "print(\n",
    "    f\" Avg Precision : {total_precision / eval_amount}\\n\",\n",
    "    f\"Avg recall : {total_recall / eval_amount}\\n\",\n",
    "    f\"Avg f1 score : {total_f1 / eval_amount}\\n\",\n",
    "    f\"Avg ground truth count : {total_gt_cnt / eval_amount}\\n\",\n",
    "    f\"Avg predicted count : {total_pred_cnt / eval_amount}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fcec5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "company_breif_pjt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
